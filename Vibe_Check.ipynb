{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Vibe Check",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "WAbECVu9FC1i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "661051ab-6cfc-4758-8bb9-1dc8bf439c06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, Javascript, Image\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode, b64encode\n",
        "import cv2\n",
        "import numpy as np\n",
        "import PIL\n",
        "import io\n",
        "import html\n",
        "import time\n",
        "import torch\n",
        "import dlib\n",
        "from skimage import io\n",
        "from scipy.spatial import distance\n",
        "from typing_extensions import runtime\n",
        "from yolov5 import detect\n",
        "from google.colab.patches import cv2_imshow\n",
        "import os"
      ],
      "metadata": {
        "id": "dRkdikmTC1VV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b887054e-c7d1-4408-d240-d6c5892863ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://ultralytics.com/assets/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbvMlHd_QwMG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb3afc74-8a51-468c-c7e7-a4a00d5da8f2"
      },
      "source": [
        "# !git clone https://github.com/ultralytics/yolov5  # clone\n",
        "# %cd yolov5\n",
        "# %pip install -qr requirements.txt  # install\n",
        "\n",
        "# from yolov5 import utils\n",
        "# display = utils.notebook_init()  # checks"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "YOLOv5 ðŸš€ v6.0-143-gd699c21 torch 1.10.0+cu111 CUDA:0 (Tesla K80, 11441MiB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setup complete âœ… (2 CPUs, 12.7 GB RAM, 42.0/78.2 GB disk)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SUNPDR2EEf0G"
      },
      "source": [
        "!unzip -q /content/drive/MyDrive/train_data.zip -d ../\n",
        "!unzip -q /content/drive/MyDrive/yoloproject.zip -d ../"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!zip -r yoloproject.zip /content/yolov5 "
      ],
      "metadata": {
        "id": "EtIvf4avoz35"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function to convert the JavaScript object into an OpenCV image\n",
        "def js_to_image(js_reply):\n",
        "  \"\"\"\n",
        "  Params:\n",
        "          js_reply: JavaScript object containing image from webcam\n",
        "  Returns:\n",
        "          img: OpenCV BGR image\n",
        "  \"\"\"\n",
        "  # decode base64 image\n",
        "  image_bytes = b64decode(js_reply.split(',')[1])\n",
        "  # convert bytes to numpy array\n",
        "  jpg_as_np = np.frombuffer(image_bytes, dtype=np.uint8)\n",
        "  # decode numpy array into OpenCV BGR image\n",
        "  img = cv2.imdecode(jpg_as_np, flags=1)\n",
        "\n",
        "  return img\n",
        "\n",
        "# function to convert OpenCV Rectangle bounding box image into base64 byte string to be overlayed on video stream\n",
        "def bbox_to_bytes(bbox_array):\n",
        "  \"\"\"\n",
        "  Params:\n",
        "          bbox_array: Numpy array (pixels) containing rectangle to overlay on video stream.\n",
        "  Returns:\n",
        "        bytes: Base64 image byte string\n",
        "  \"\"\"\n",
        "  # convert array into PIL image\n",
        "  bbox_PIL = PIL.Image.fromarray(bbox_array, 'RGBA')\n",
        "  iobuf = io.BytesIO()\n",
        "  # format bbox into png for return\n",
        "  bbox_PIL.save(iobuf, format='png')\n",
        "  # format return string\n",
        "  bbox_bytes = 'data:image/png;base64,{}'.format((str(b64encode(iobuf.getvalue()), 'utf-8')))\n",
        "\n",
        "  return bbox_bytes"
      ],
      "metadata": {
        "id": "vyWig_dPC7cz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = torch.hub.load('ultralytics/yolov5', 'custom', path='/content/yolov5/runs/train/exp/weights/best.pt')"
      ],
      "metadata": {
        "id": "k13a61vQHIOK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "face_cascade = model"
      ],
      "metadata": {
        "id": "GgpuaeUsC80l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# JavaScript to properly create our live video stream using our webcam as input\n",
        "def video_stream():\n",
        "  js = Javascript('''\n",
        "    var video;\n",
        "    var div = null;\n",
        "    var stream;\n",
        "    var captureCanvas;\n",
        "    var imgElement;\n",
        "    var labelElement;\n",
        "    \n",
        "    var pendingResolve = null;\n",
        "    var shutdown = false;\n",
        "    \n",
        "    function removeDom() {\n",
        "       stream.getVideoTracks()[0].stop();\n",
        "       video.remove();\n",
        "       div.remove();\n",
        "       video = null;\n",
        "       div = null;\n",
        "       stream = null;\n",
        "       imgElement = null;\n",
        "       captureCanvas = null;\n",
        "       labelElement = null;\n",
        "    }\n",
        "    \n",
        "    function onAnimationFrame() {\n",
        "      if (!shutdown) {\n",
        "        window.requestAnimationFrame(onAnimationFrame);\n",
        "      }\n",
        "      if (pendingResolve) {\n",
        "        var result = \"\";\n",
        "        if (!shutdown) {\n",
        "          captureCanvas.getContext('2d').drawImage(video, 0, 0, 640, 480);\n",
        "          result = captureCanvas.toDataURL('image/jpeg', 0.8)\n",
        "        }\n",
        "        var lp = pendingResolve;\n",
        "        pendingResolve = null;\n",
        "        lp(result);\n",
        "      }\n",
        "    }\n",
        "    \n",
        "    async function createDom() {\n",
        "      if (div !== null) {\n",
        "        return stream;\n",
        "      }\n",
        "\n",
        "      div = document.createElement('div');\n",
        "      div.style.border = '2px solid black';\n",
        "      div.style.padding = '3px';\n",
        "      div.style.width = '100%';\n",
        "      div.style.maxWidth = '600px';\n",
        "      document.body.appendChild(div);\n",
        "      \n",
        "      const modelOut = document.createElement('div');\n",
        "      modelOut.innerHTML = \"<span>Status:</span>\";\n",
        "      labelElement = document.createElement('span');\n",
        "      labelElement.innerText = 'No data';\n",
        "      labelElement.style.fontWeight = 'bold';\n",
        "      modelOut.appendChild(labelElement);\n",
        "      div.appendChild(modelOut);\n",
        "           \n",
        "      video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      video.width = div.clientWidth - 6;\n",
        "      video.setAttribute('playsinline', '');\n",
        "      video.onclick = () => { shutdown = true; };\n",
        "      stream = await navigator.mediaDevices.getUserMedia(\n",
        "          {video: { facingMode: \"environment\"}});\n",
        "      div.appendChild(video);\n",
        "\n",
        "      imgElement = document.createElement('img');\n",
        "      imgElement.style.position = 'absolute';\n",
        "      imgElement.style.zIndex = 1;\n",
        "      imgElement.onclick = () => { shutdown = true; };\n",
        "      div.appendChild(imgElement);\n",
        "      \n",
        "      const instruction = document.createElement('div');\n",
        "      instruction.innerHTML = \n",
        "          '<span style=\"color: red; font-weight: bold;\">' +\n",
        "          'When finished, click here or on the video to stop this demo</span>';\n",
        "      div.appendChild(instruction);\n",
        "      instruction.onclick = () => { shutdown = true; };\n",
        "      \n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "\n",
        "      captureCanvas = document.createElement('canvas');\n",
        "      captureCanvas.width = 640; //video.videoWidth;\n",
        "      captureCanvas.height = 480; //video.videoHeight;\n",
        "      window.requestAnimationFrame(onAnimationFrame);\n",
        "      \n",
        "      return stream;\n",
        "    }\n",
        "    async function stream_frame(label, imgData) {\n",
        "      if (shutdown) {\n",
        "        removeDom();\n",
        "        shutdown = false;\n",
        "        return '';\n",
        "      }\n",
        "\n",
        "      var preCreate = Date.now();\n",
        "      stream = await createDom();\n",
        "      \n",
        "      var preShow = Date.now();\n",
        "      if (label != \"\") {\n",
        "        labelElement.innerHTML = label;\n",
        "      }\n",
        "            \n",
        "      if (imgData != \"\") {\n",
        "        var videoRect = video.getClientRects()[0];\n",
        "        imgElement.style.top = videoRect.top + \"px\";\n",
        "        imgElement.style.left = videoRect.left + \"px\";\n",
        "        imgElement.style.width = videoRect.width + \"px\";\n",
        "        imgElement.style.height = videoRect.height + \"px\";\n",
        "        imgElement.src = imgData;\n",
        "      }\n",
        "      \n",
        "      var preCapture = Date.now();\n",
        "      var result = await new Promise(function(resolve, reject) {\n",
        "        pendingResolve = resolve;\n",
        "      });\n",
        "      shutdown = false;\n",
        "      \n",
        "      return {'create': preShow - preCreate, \n",
        "              'show': preCapture - preShow, \n",
        "              'capture': Date.now() - preCapture,\n",
        "              'img': result};\n",
        "    }\n",
        "    ''')\n",
        "\n",
        "  display(js)\n",
        "  \n",
        "def video_frame(label, bbox):\n",
        "  data = eval_js('stream_frame(\"{}\", \"{}\")'.format(label, bbox))\n",
        "  return data"
      ],
      "metadata": {
        "id": "6tvgaldmC_iD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_list=['/content/drive/MyDrive/dlib w/dima2.jpg','/content/drive/MyDrive/dlib w/gonya3.jpg','/content/drive/MyDrive/dlib w/gigachad.jpg']\n",
        "sp = dlib.shape_predictor('/content/drive/MyDrive/dlib w/shape_predictor_68_face_landmarks.dat')\n",
        "facerec = dlib.face_recognition_model_v1('/content/drive/MyDrive/dlib w/dlib_face_recognition_resnet_model_v1.dat')\n",
        "detector = dlib.get_frontal_face_detector()"
      ],
      "metadata": {
        "id": "taSJnUsn-o4G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def descriptor_get(img_list,sp,facerec,detector):\n",
        "  descriptor_list=[]\n",
        "  for face in img_list:\n",
        "      img = io.imread(face)\n",
        "      dets = detector(img,1)\n",
        "      for k,d in enumerate(dets):\n",
        "        shape = sp(img, d)\n",
        "      descriptor_list.append(facerec.compute_face_descriptor(img, shape))\n",
        "  return descriptor_list"
      ],
      "metadata": {
        "id": "xb2GQym0-vm8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "desc= descriptor_get(img_list,sp,facerec,detector)"
      ],
      "metadata": {
        "id": "TrpMcDkv_RDi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dlibface(image,desc,sp,facerec,detector):\n",
        "    img = io.imread(image)  \n",
        "    dets = detector(img, 1)\n",
        "    if not dets:\n",
        "      return 'authfailed'\n",
        "    for face in desc:\n",
        "      for k,d in enumerate(dets):\n",
        "        shape = sp(img, d)\n",
        "      face_descriptor = facerec.compute_face_descriptor(img, shape)\n",
        "      a = distance.euclidean(face, face_descriptor)  \n",
        "      print(a)\n",
        "      if a < 0.6: \n",
        "        return 'authsuccess'\n",
        "    return 'authfailed'"
      ],
      "metadata": {
        "id": "pAgRl6GdpbZl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# start streaming video from webcam\n",
        "video_stream()\n",
        "# label for video\n",
        "label_html = 'Capturing...'\n",
        "# initialze bounding box to empty\n",
        "bbox = ''\n",
        "count = 0 \n",
        "while True:\n",
        "    js_reply = video_frame(label_html, bbox)\n",
        "    if not js_reply:\n",
        "        break\n",
        "    # convert JS response to OpenCV Image\n",
        "    img = js_to_image(js_reply[\"img\"])\n",
        "\n",
        "    # create transparent overlay for bounding box\n",
        "    bbox_array = np.zeros([480,640,4], dtype=np.uint8)\n",
        "\n",
        "    # grayscale image for face detection\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "\n",
        "    # get face region coordinates\n",
        "    im = cv2_imshow(img)\n",
        "    count+=1\n",
        "    cv2.imwrite(f'/content/drive/MyDrive/photo{count}.jpg', img)\n",
        "    # im = model(img)\n",
        "    # im.show()\n",
        "    detect.run(weights='/content/yolov5/runs/train/exp/weights/best.pt', imgsz=(640,640), conf_thres=0.25, source=f'/content/drive/MyDrive/photo{count}.jpg', save_crop=True)\n",
        "    try:\n",
        "      if os.path.isdir(f'/content/yolov5/runs/detect/exp{137+count}/crops'):\n",
        "        result = dlibface(f'/content/yolov5/runs/detect/exp{137+count}/crops/person/photo{count}.jpg',desc,sp,facerec,detector)\n",
        "        print(result)\n",
        "      else:\n",
        "        raise RuntimeError \n",
        "    except RuntimeError:\n",
        "      print(\"Not detected\")\n",
        "      pass"
      ],
      "metadata": {
        "id": "UX359LAEL01w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zR9ZbuQCH7FX"
      },
      "source": [
        "#TEST\n",
        "#!python detect.py --weights runs/train/exp/weights/best.pt --img 640 --conf 0.25 --source '/content/drive/MyDrive/dlib w/gosha.mp4' --save-crop \n",
        "detect.run(weights='/content/yolov5/runs/train/exp/weights/best.pt', imgsz=(640,640), conf_thres=0.25, source='/content/dimachad.jpg', save_crop=True)\n",
        "#display(Image(filename='/content/yolov5/runs/detect/exp15/photo.jpg'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dlibface('/content/drive/MyDrive/dlib w/dima2.jpg',desc,sp,facerec,detector)"
      ],
      "metadata": {
        "id": "X-JJiIabpDcy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1NcFxRcFdJ_O"
      },
      "source": [
        "#TRAIN\n",
        "!python train.py --img 640 --batch 6 --epochs 60 --data /content/drive/MyDrive/custom_data.yaml --weights yolov5s.pt --cache "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir runs"
      ],
      "metadata": {
        "id": "2ovViZMQslp7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from pycocotools.coco import COCO\n",
        "# import requests\n",
        "\n",
        "# coco = COCO('/content/datasets/coco/annotations/instances_val2017.json')\n",
        "# # Specify a list of category names of interest\n",
        "# catIds = coco.getCatIds(catNms=['person'])\n",
        "# # Get the corresponding image ids and images using loadImgs\n",
        "# imgIds = coco.getImgIds(catIds=catIds)\n",
        "# images = coco.loadImgs(imgIds)"
      ],
      "metadata": {
        "id": "G4TT1zCfI5kz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Save the images into a local folder\n",
        "# for im in images:\n",
        "#     img_data = requests.get(im['coco_url']).content\n",
        "#     with open('/content/drive/MyDrive/coco_person/' + im['file_name'], 'wb') as handler:\n",
        "#         handler.write(img_data)"
      ],
      "metadata": {
        "id": "ruHo2nbxKPSQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}